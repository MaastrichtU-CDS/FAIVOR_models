{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIRmodels.org validation notebook\n",
    "\n",
    "This notebook performs an initial validation of a given AI model. The AI model is described and packaged using the repository at [https://fairmodels.org](https://fairmodels.org).\n",
    "\n",
    "This notebook assumes metadata according to [https://fairmodels.org](https://fairmodels.org), and packaged into an image using [https://github.com/MaastrichtU-BISS/FAIRmodels-model-package](https://github.com/MaastrichtU-BISS/FAIRmodels-model-package).\n",
    "\n",
    "The first step below is to identify the:\n",
    "\n",
    "- URI (URL) of the model metadata\n",
    "- Dataset for validation (currently excel sheet)\n",
    "- Outcome parameter/column in the dataset\n",
    "\n",
    "The current notebook assumes a classification problem, however the last cell in the notebook can be adapted to accomodate different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://v2.fairmodels.org/instance/3f400afb-df5e-4798-ad50-0687dd439d9b\"\n",
    "validation_filename = \"thunder_reduced.xlsx\"\n",
    "outcome_parameter = 'pCR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install needed dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docker in c:\\users\\j.vansoest\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (7.1.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\j.vansoest\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker) (306)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\j.vansoest\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\j.vansoest\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from docker) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\j.vansoest\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->docker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\j.vansoest\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->docker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\j.vansoest\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->docker) (2024.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch information about model\n",
    "Fetch model metadata based on the URI of the model metadata, pull the docker image from the repository, and run the model locally on a random port (bound to localhost only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch model metadata from URL, and specifically request the accept type as JSON-LD\n",
    "import requests\n",
    "import json\n",
    "\n",
    "response = requests.get(url, headers={'Accept': 'application/ld+json'})\n",
    "model_metadata = json.loads(response.text)\n",
    "docker_image_name = model_metadata['FAIRmodels image name']['@value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull docker image\n",
    "import docker\n",
    "client = docker.from_env()\n",
    "try:\n",
    "    client.images.pull(docker_image_name)\n",
    "except docker.errors.APIError as e:\n",
    "    print(\"could not pull image: \", e)\n",
    "\n",
    "# run docker image and expose port 8000 to a random port which is freely available\n",
    "import socket\n",
    "import random\n",
    "\n",
    "port = random.randint(49152, 65535)\n",
    "# check if port is available\n",
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    while s.connect_ex(('localhost', port)) == 0:\n",
    "        port = random.randint(49152, 65535)\n",
    "\n",
    "container = client.containers.run(docker_image_name, detach=True, ports={8000:port}, remove=True)\n",
    "\n",
    "# wait for the server to start\n",
    "import time\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess model input parameters\n",
    "\n",
    "Based on the docker image, find the input parameter column names. Afterwards, test in the excel sheet whether these columns can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: ['cT', 'cN', 'tLength']\n"
     ]
    }
   ],
   "source": [
    "# get the JSON from the root webpage in the container\n",
    "image_root_url = f\"http://localhost:{port}\"\n",
    "response = requests.get(image_root_url)\n",
    "data = response.json()\n",
    "\n",
    "# get input/output parameters of the first model\n",
    "model_parameters = data[\"path_parameters\"]\n",
    "print(f\"Model parameters: {model_parameters}\")\n",
    "\n",
    "columns = model_parameters + [outcome_parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: ['tLength']\n"
     ]
    }
   ],
   "source": [
    "# read excel sheet as input data using pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "input_data = pd.read_excel(validation_filename)\n",
    "\n",
    "def check_columns_exist(input_data, columns, raise_exception=False):\n",
    "    \"\"\"\n",
    "    Check if all columns exist in the input data\n",
    "\n",
    "    :param input_data: pandas dataframe\n",
    "    :param columns: list of columns\n",
    "    :param raise_exception: boolean, if True, raise exception if columns are missing, otherwise print missing columns\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    missing_columns = []\n",
    "    for column in columns:\n",
    "        if column not in input_data.columns:\n",
    "            missing_columns.append(column)\n",
    "    \n",
    "    # if there are missing columns, throw exception\n",
    "    if len(missing_columns) > 0:\n",
    "        if raise_exception:\n",
    "            raise ValueError(f\"Missing columns: {missing_columns}\")\n",
    "        else:\n",
    "            print(f\"Missing columns: {missing_columns}\")\n",
    "    else:\n",
    "        print(\"All columns exist\")\n",
    "\n",
    "check_columns_exist(input_data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns exist\n"
     ]
    }
   ],
   "source": [
    "# rename column \"SizeZ\" to \"tLength\"\n",
    "input_data = input_data.rename(columns={\"SizeZ\": \"tLength\"})\n",
    "check_columns_exist(input_data, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of model (inferencing)\n",
    "\n",
    "In the following section, the input data is sent to the model for inferencing, and results are retrieved.\n",
    "\n",
    "When execution is done, the model container is stopped and removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model triggered with input data, Prediction completed\n"
     ]
    }
   ],
   "source": [
    "# replace all cells with \"x\" to NA\n",
    "input_data = input_data.replace(\"x\", pd.NA)\n",
    "\n",
    "# input data should only contain complete cases\n",
    "input_data = input_data.dropna(subset=columns)\n",
    "\n",
    "# convert pandas dataframe to JSON, but only for the columns specified in the model\n",
    "input_data_json = json.loads(input_data[columns].to_json(orient='records'))\n",
    "\n",
    "# send the input data to the model\n",
    "response = requests.post(f\"http://localhost:{port}/predict\", json=input_data_json)\n",
    "\n",
    "# send the input data to the model\n",
    "response = requests.get(f\"http://localhost:{port}/status\", json=input_data_json)\n",
    "print(f\"Model triggered with input data, {response.json()['message']}\")\n",
    "\n",
    "if response.json()[\"status\"] != 3:\n",
    "    raise AppError(\"Prediction model execution exited with an error message\")\n",
    "\n",
    "# fetch model results\n",
    "response = requests.get(f\"http://localhost:{port}/result\")\n",
    "input_data['predictions'] = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the running container\n",
    "container.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate performance metrics\n",
    "\n",
    "Now we can calculate the performance metrics. For demonstration purposes, only AUC and Brier score are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: {'AUC': 0.6988795518207283, 'Brier': 0.18465341199853313}\n"
     ]
    }
   ],
   "source": [
    "# convert outcome parameter to boolean\n",
    "input_data[outcome_parameter] = input_data[outcome_parameter] == 1\n",
    "\n",
    "# calculate AUC\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "auc = roc_auc_score(input_data[outcome_parameter], input_data['predictions'])\n",
    "\n",
    "# calculate brier score\n",
    "brier = brier_score_loss(input_data[outcome_parameter], input_data['predictions'])\n",
    "\n",
    "scores = {\n",
    "    \"AUC\": auc,\n",
    "    \"Brier\": brier\n",
    "}\n",
    "\n",
    "print(f\"Scores: {scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
